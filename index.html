<!DOCTYPE html>
<html>

<head>
  <style>
    .nowrap {
      white-space: nowrap;
    }
    .gain {
      color: red;
  }
  </style>
  <meta charset="utf-8">
  <meta name="description" content="HonestLLM: Toward an Honest and Helpful Large Language Model">
  <meta name="keywords" content="LLM, Honesty, Alignment, Finetune, Dataset, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HonestLLM: Toward an Honest and Helpful Large Language Model</title>
  <script type="module" src="https://md-block.verou.me/md-block.js"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./img/gui-logo.jpg">

  <link rel="stylesheet" href="./stylesheets/layout.css">
  <link rel="stylesheet" href="./stylesheets/index.css">
  <link rel="stylesheet" href="./bowe_componets/css/bootstrap.table.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link href="./static/css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="./static/css/custom.css" media="screen" rel="stylesheet" type="text/css" />
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://flossiee.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://gui-world.github.io">
              GUI-World
            </a>
            <a class="navbar-item" href="https://trustllmbenchmark.github.io/TrustLLM-Website/">
              TrustLLM
            </a>
            <a class="navbar-item" href="https://mllm-judge.github.io">
              MLLM-as-a-Judge
            </a>
            <a class="navbar-item" href="https://unigen-framework.github.io/">
              UniGen
            </a>
            <a class="navbar-item" href="https://llm-coauthor.github.io/">
              LLM-as-a-Coauthor
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              The Best of Both Worlds: Toward an Honest and Helpful Large Language Model
            </h1>
            <div class="is-size-5 publication-authors">
              NeurIPS 2024
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://flossiee.github.io/">Chujie Gao</a><sup style="color:#25c892;">1</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://siyuan-5.github.io/">Siyuan Wu<a></a><sup style="color:#ec8bfd;">2</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://howiehwong.github.io/">Yue Huang</a><sup style="color:#2bff32;">3</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://dongping-chen.github.io/">Dongping Chen</a><sup style="color:#ec8bfd;">2</sup><sup style="color:#4cb32f;">4</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block"><a href="https://mask-hui.github.io/">Qihui Zhang</a><sup style="color:#94990b;">5</sup><sup style="color:#ff2b67;">*</sup>,</span>
              <span class="author-block">Zhengyan Fu<sup style="color:#ec8bfd;">2</sup>,</span>
              <span class="author-block"><a href="http://wanyao.me/">Yao Wan</a><sup style="color:#ec8bfd;">2</sup><sup style="color:#c9892e;">†</sup>,</span>
              <span class="author-block"><a href="https://lichao-sun.github.io/">Lichao Sun</a><sup style="color:#bc4848;">6</sup><sup style="color:#c9892e;">†</sup></span>,
              <span class="author-block"><a href="https://engineering.nd.edu/faculty/xiangliang-zhang/">Xiangliang Zhang</a><sup style="color:#2bff32;">3</sup><sup style="color:#c9892e;">†</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup style="color:#25c892;">1</sup>MUZUAI</span>
              <span class="author-block"><sup style="color:#ec8bfd;">2</sup>Huazhong University of Science andTechnology,</span>
              <br>
              <span class="author-block"><sup style="color:#2bff32;">3</sup>University of Notre Dame,</span>
              <span class="author-block"><sup style="color:#4cb32f;">4</sup>University of Washington</span>
              <br>
              <span class="author-block"><sup style="color:#94990b;">5</sup>Peking University</span>
              <span class="author-block"><sup style="color:#bc4848;">6</sup>Lehigh University</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="mailto:gaochujie1107@gmail.com">gaochujie1107@gmail.com</a></span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!--                <span class="link-block">-->
                <!--                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">-->
                <!--                    <span class="icon">-->
                <!--                      <i class="fas fa-file-pdf"></i>-->
                <!--                    </span>-->
                <!--                    <span>Paper</span>-->
                <!--                  </a>-->
                <!--                </span>-->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.00380" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!--                <span class="link-block">-->
                <!--                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
                <!--                    class="external-link button is-normal is-rounded is-dark">-->
                <!--                    <span class="icon">-->
                <!--                      <i class="fab fa-youtube"></i>-->
                <!--                    </span>-->
                <!--                    <span>Video</span>-->
                <!--                  </a>-->
                <!--                </span>-->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Flossiee/HonestyLLM"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/datasets/shuaishuaicdp/GUI-World"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span> -->
                <!-- Data Viewer. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/shuaishuaicdp/GUI-Vid" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-desktop"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span> -->
                <!-- Slides Link. -->
                <!-- <span class="link-block">
                  <a href="https://docs.google.com/presentation/d/1-r889Nb9n7SeZqrj-ryNqJLoMzp7aGNU2ihO8nUdEcE/edit?usp=sharing"
                    target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google"></i>
                    </span>
                    <span>Slides</span>
                  </a>
                </span> -->
                <!-- Twitter Link. -->
                <!-- <span class="link-block">
                  <a href="https://twitter.com/TianbaoX/status/1778781521253667267" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-twitter"></i>
                    </span>
                    <span>Twitter</span>
                  </a>
                </span> -->
                <!-- Discord Link. -->
                <!-- <span class="link-block">
                  <a href="https://discord.gg/4Gnw7eTEZR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-discord"></i>
                    </span>
                    <span>Discord</span>
                  </a>
                </span> -->

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full">
        <video controls muted loop autoplay width="100%">
          <source src="static/videos/main.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Main Figure. -->
      <h2 class="title is-3"></h2>
      <div class="content has-text-justified">
        <img src="img/honest-framework2.png" width="100%" alt="GUI-world Benchmark Overview" class="responsive-image">
        <md-block>
          We establish exhaustive principles aimed at guaranteeing the honesty of LLM and propose HONESET, as well as
          two methods to enhance the honesty and helpfulness of LLMs. In summary, the primary contributions of this
          paper are as follows:
          <ol>
            <li><b>Definitions for Honesty.</b> We refine a comprehensive definition of honesty in LLMs and establish
              detailed principles that honest LLMs should adhere to. Based on these principles, we construct a new
              dataset, <b>HONESET</b>, which contains queries from six categories designed to evaluate LLMs’ ability to
              maintain honesty. </li>
            <li><b>Two Methods.</b> We introduce a training-free approach based on curiosity-driven prompting, alongside
              a curriculum learning-based approach with a two-stage fine-tuning process, to enhance the helpfulness of
              both proprietary and open-source LLMs while maintaining their honesty. </li>
            <li><b>Comprehensive Experiments and Valuable Insights.</b> We conduct extensive experiments on nine LLMs,
              including both open-source and proprietary models, using two evaluation protocols. The experimental
              results show that both of our proposed methods significantly improve the honesty and helpfulness of LLMs.
            </li>
          </ol>
        </md-block>
      </div>
      <!--/ Main Figure. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-wdith">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <md-block>
              Large Language Models (LLMs) have achieved remarkable success across various industries due to their
              exceptional generative capabilities. However, for safe and effective real-world deployments, ensuring
              honesty and helpfulness is critical. This paper addresses the question: ***Can we prioritize the
              helpfulness
              of LLMs while preserving their honesty?*** To begin with, we establish exhaustive principles aimed at
              guaranteeing the honesty of LLM. Additionally, we introduce a novel dataset, referred to as **HONESET**,
              comprising 930 queries spanning six categories meticulously crafted to assess an LLM’s capacity for
              maintaining honesty. Subsequently, we present two approaches to augmenting honesty and helpfulness in
              LLMs: a training-free enhancement and a fine-tuning-based improvement. The training-free approach, which
              is based on curiosity-driven prompting, empowers LLMs to articulate internal confusion and uncertainty
              regarding queries, thereby optimizing their responses. Conversely, the fine-tuning-based method employs a
              two-stage process inspired by curriculum learning: initially instructing LLMs to discern between honest
              and dishonest responses, then refining their training to enhance helpfulness. Experiments conducted on
              nine prominent LLMs demonstrate a significant improvement in alignment with honesty across all models
              through the implementation of our proposed enhancements. Particularly noteworthy is the 65.3% enhancement
              observed in Llama3-8b and the remarkable 124.7% improvement in Mistral-7b, as measured by the H2 (honest
              and helpful) assessment. We believe that our work can pave the way for developing more trustworthy LLMs
              for real-world applications.
            </md-block>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Environment Infrastructure. -->
      <h2 class="title is-3">Principles for Honest LLMs</h2>
      <div class="content has-text-justified">
        <img src="img/principles.png" width="100%" alt="environment infrastructure" class="responsive-image">
        <md-block>we propose the principles of honest LLMs as shown in Appendix A,
          which focus on six categories*:
          <ol>
            <li><b>Latest Information with External Services.</b> Due to outdated pre-training data, insufficient
              fact-checking, and lack of access to live or up-to-date external data sources, LLMs may produce seemingly
              reasonable but inaccurate output when accessing the latest information via external tools. As a result,
              honestly acknowledging these limitations is crucial.</li>
            <li><b>User Input Not Enough Or With Wrong Information.</b> In the real world, LLMs frequently face
              incorrect or ambiguous questions. LLMs must avoid sycophancy and provide truthful, honest responses
              to maintain objectivity and prevent undue influence from user inputs.</li>
            <li><b>Professional Capability in Specific Domains.</b> Domain-specific tasks challenge LLMs beyond their
              capabilities because of the rapid updates in professional fields and the need for extensive, high-quality,
              task-specific datasets. Given the diverse constraints, LLMs are expected to honestly recognize their
              limitations and avoid unreliable outputs.</li>
            <li><b>Interactivity Sensory Processing.</b> LLMs are unable to directly perceive and process sensory data
              (such as sound or tactile feedback), which are crucial for interactive tasks. The honesty of LLMs would
              include acknowledging that they cannot directly interact with the physical world.</li>
            <li><b>Modality Mismatch.</b> LLMs are designed for processing text-based inputs and outputs, therefore,
              they face challenges in understanding or generating non-text modal data (such as images, and audio). This
              mismatch can lead to incorrect or irrelevant responses, which underscores the need for LLMs to honestly
              acknowledge the limitations in handling these types of data.</li>
            <li><b>Self Identity Cognition.</b> As a helpful and honest assistant, an LLM should possess a clear
              selfawareness, recognize the distinctions between humans and AI assistant, and renounce its self-identity
              when addressing topics that humans can perceive and understand but AI cannot, such as social and
              introspective awareness.</li>
          </ol>
        </md-block>
      </div>
      <!--/ Environment Infrastructure. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-wdith">
          <h2 class="title is-3">Approach I: Training-Free Enhancement</h2>
          <img src="img/honest-framework.png" width="100%" alt="HonestLLM Overview" class="responsive-image">
          <div class="content has-text-justified">
            <md-block>
              **Curiosity-Driven Prompting** Intuitively, when faced with queries that require a high degree of honesty
              (e.g., questions outside the LLM’s capabilities or those it cannot adequately address), there arises an
              inherent uncertainty within the LLM. Recent research has explored methods for utilizing LLM outputs to
              quantify such uncertainties, including the generation of confidence scores alongside responses. This has
              inspired us to employ LLM’s awareness of their uncertainty in addressing given queries. In essence, as LLM
              is engineered to be helpful, this uncertainty can be transformed into curiosity, which in turn may drive
              them to provide more accurate responses to user queries.
            </md-block>
            <md-block>
              **Optimizing Output** The curiosity-driven prompt approach enhances LLM honesty by using LLM outputs as a
              basis for improvement. Inspired by self-alignment studies, a constitution-guided prompt combines the
              query, raw answer, and expressed confusion, and feeds it back into the LLMs to generate improved, helpful,
              and honest responses. This prompt ensures LLMs express uncertainties as disclaimers and provide actionable
              guidance, such as suggesting practical alternatives for complex tasks.
            </md-block>
          </div>

          <h2 class="title is-3">Approach II: Curriculum Fine-Tuning</h2>
          <div class="content has-text-justified">
            <md-block>

            </md-block>
            <md-block>
              **Stage One: Differentiating Honesty from Dishonesty.** The primary goal of this stage is to train
              LLMs to distinguish between honest and dishonest responses. We only retain response pairs with
              contrasting honesty evaluations for training.
            </md-block>
            <md-block>
              **Stage Two: Enhancing Overall Response Quality.** The second stage is dedicated to enhancing the
              overall quality of responses, aiming to produce outcomes that are not only honest but also informative
              and helpful. These pairs are utilized to further refine the LLM through the DPO framework. This two-stage
              fine-tuning process ensures that LLMs adhere to honesty
              standards while fostering the generation of helpful, high-quality guidance in practical scenarios.
            </md-block>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Benchmark</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-wdith">
          <div class="content has-text-justified">
            <ol>
              <li><b>Models. </b>Our study covers nine mainstream LLMs, including both open-source and proprietary LLMs.
                Our evaluation came across ChatGPT and GPT-4 by OpenAI; Llama2 (7b-chat, 13b-chat, 70b-chat) and
                Llama3-70b-instruct by Meta AI; Mistral-7b and Mixtral-8x7b by Mistral AI; and Claude3-Opus by
                Anthropic.</li>
              <li><b>Metrics. </b>Our evaluation framework consists of two protocols: one focusing on honesty and the
                other on both honesty and helpfulness. Due to the complexity of rule-based methods like keyword
                matching, we use the “LLM-as-a-Judge” methodology, widely used in previous studies. Each response is
                judged by averaging the results of three rounds of LLM-as-a-Judge. We propose two evaluation protocols
                as follows:<ul>
                  <li><b>Purely Honest-Guided Evaluation.</b> This protocol aims to gauge the adherence of LLMs to
                    honesty. LLMs are evaluated against predefined criteria specified in Table 4. An LLM is deemed
                    honest if its responses consistently align with these standards. For this evaluation, we use the
                    "Honesty Rate" metric, which quantifies the percentage of queries in which an LLM consistently
                    exhibits honesty.</li>
                  <li><b>H2 Assessment.</b> This protocol evaluates both honesty and helpfulness (H2). It requires LLMs
                    to not only uphold honesty but also provide well-reasoned explanations, justifications, and viable
                    solutions for user inquiries. The H2 assessment is based on three main criteria: (1) Rationality of
                    Explanations for Honesty or Disclaimers, (2) Quality of Further Guidance, and (3) Potential
                    Solutions. Criteria (1) and (2) are crucial as they directly reflect the model’s honesty and
                    helpfulness, while (3) is secondary. The importance of these criteria is weighted accordingly in our
                    evaluation. Additionally, the H2 protocol uses both pairwise and score-based evaluation formats to
                    comprehensively assess responses.</li>
                </ul>
              </li>
            </ol>
          </div>
        </div>
      </div>
    </div>
    <div class="cover" id="contentCover">
      <!-- Baseline. -->
      <div class="container-t">
        <div class="row">
          <div class="col-md-12">
            <div class="infoCard">
              <div class="infoBody">
                <div class="tabs is-centered example_lst">
                  <ul>
                    <li class="is-active"><a title="Overall"><b>Overall</b></a></li>
                    <li><a title="Curiosity-Driven"><b>Curiosity-Driven</b></a></li>
                    <li><a title="Finetuning"><b>Finetuning</b></a></li>
                    <li><a title="Ablation Study for Curriculum Learning"><b>Ablation Study for Curriculum Learning</b></a>
                    </li>
                  </ul>

                </div>
                <script type="text/javascript">
                  document.querySelectorAll(".example_lst li").forEach(e => {
                    e.addEventListener("click", Click_1)
                  })

                  function Click_1(eve) {
                    const iTxt = eve.srcElement.innerText
                    for (let v of document.querySelectorAll(".example_lst a")) {
                      if (iTxt === v.innerText) {
                        v.parentElement.className = "is-active";
                      } else {
                        v.parentElement.className = "";
                      }
                    }
                    for (let block of document.getElementsByClassName('lib_examples')) {
                      block.style.display = (block.title === iTxt) ? 'block' : 'none';
                    }
                  }

                </script>
                <div title="Overall" class="lib_examples" id="BoardPanel1" style="display: block;">
                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Improvements in honesty rate and H2
                    scores for Llama3-8b and Mistral-7b after Curiosity-Driven method.
                  </md-block>
                  <!-- </div> -->
                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Model</th>
                          <th colspan="2" class="nowrap">1~3 (Poor, ↓)</th>
                          <th colspan="2" class="nowrap">4~6 (Medium, ↓)</th>
                          <th colspan="2" class="nowrap">7~10 (Excellent, ↑)</th>
                          <th colspan="3" class="nowrap">Overall(↑)</th>
                        </tr>
                        <tr>
                          <th>raw</th>
                          <th>opt.</th>
                          <th>raw</th>
                          <th>opt.</th>
                          <th>raw</th>
                          <th>opt.</th>
                          <th>raw</th>
                          <th>opt.</th>
                          <th>gain</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr class="highlight">
                          <td colspan="10"><strong>Proprietary Model</strong></td>
                        </tr>
                        <tr>
                          <td><strong>GPT4</strong></td>
                          <td><strong>2.5%</strong></td>
                          <td><strong>0.1%</strong></td>
                          <td><strong>10.1%</strong></td>
                          <td><strong>2.5%</strong></td>
                          <td><strong>87.6%</strong></td>
                          <td><strong>97.3%</strong></td>
                          <td><strong>8.094</strong></td>
                          <td><strong>8.604</strong></td>
                          <td class="gain">6.3%↑</td>
                        </tr>
                        <tr>
                          <td><strong>ChatGPT</strong></td>
                          <td>38.5%</td>
                          <td>11.1%</td>
                          <td>20.1%</td>
                          <td>26.9%</td>
                          <td>41.4%</td>
                          <td>62.0%</td>
                          <td>5.098</td>
                          <td>6.770</td>
                          <td class="gain">32.8%↑</td>
                        </tr>
                        <tr>
                          <td><strong>Claude3-Opus</strong></td>
                          <td>14.4%</td>
                          <td>0.9%</td>
                          <td>17.0%</td>
                          <td>9.2%</td>
                          <td>68.6%</td>
                          <td>89.9%</td>
                          <td>7.061</td>
                          <td>8.244</td>
                          <td class="gain">16.8%↑</td>
                        </tr>
                        <tr class="highlight">
                          <td colspan="10"><strong>Open-Source Model</strong></td>
                        </tr>
                        <tr>
                          <td><strong>Mistral-7b</strong></td>
                          <td>55.3%</td>
                          <td>21.7%</td>
                          <td>20.4%</td>
                          <td>27.5%</td>
                          <td>24.4%</td>
                          <td>50.8%</td>
                          <td>3.885</td>
                          <td>6.046</td>
                          <td class="gain"><b>55.6%↑</b></td>
                        </tr>
                        <tr>
                          <td><strong>Mixtral-8x7b</strong></td>
                          <td>31.4%</td>
                          <td>2.8%</td>
                          <td>18.1%</td>
                          <td>15.5%</td>
                          <td>50.5%</td>
                          <td>81.7%</td>
                          <td>5.693</td>
                          <td>7.626</td>
                          <td class="gain">34.0%↑</td>
                        </tr>
                        <tr>
                          <td><strong>Llama2-7b</strong></td>
                          <td>42.9%</td>
                          <td>23.2%</td>
                          <td>19.1%</td>
                          <td>17.2%</td>
                          <td>38.0%</td>
                          <td>59.6%</td>
                          <td>4.877</td>
                          <td>6.203</td>
                          <td class="gain">27.2%↑</td>
                        </tr>
                        <tr>
                          <td><strong>Llama2-13b</strong></td>
                          <td>42.7%</td>
                          <td>24.9%</td>
                          <td>19.0%</td>
                          <td>22.1%</td>
                          <td>38.4%</td>
                          <td>53.0%</td>
                          <td>4.890</td>
                          <td>5.961</td>
                          <td class="gain">21.9%↑</td>
                        </tr>
                        <tr>
                          <td><strong>Llama2-70b</strong></td>
                          <td>39.4%</td>
                          <td>21.0%</td>
                          <td>19.7%</td>
                          <td>14.8%</td>
                          <td>40.9%</td>
                          <td>64.2%</td>
                          <td>5.068</td>
                          <td>6.447</td>
                          <td class="gain">27.2%↑</td>
                        </tr>
                        <tr>
                          <td><strong>Llama3-70b</strong></td>
                          <td>25.3%</td>
                          <td>4.2%</td>
                          <td>20.8%</td>
                          <td>14.5%</td>
                          <td>53.9%</td>
                          <td>81.3%</td>
                          <td>6.128</td>
                          <td>7.783</td>
                          <td class="gain">27.0%↑</td>
                        </tr>
                      </tbody>
                    </table>
                  </div>
                </div>

                <div title="Curiosity-Driven" class="lib_examples" id="BoardPanel2" style="display: none;">
                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Comprehensive evaluation results of the training-free method.
                  </md-block>
                  <!-- </div> -->

                  <img src="img/curiosity-driven.png" width="100%" alt="environment infrastructure"
                    class="responsive-image">
                </div>

                <div title="Finetuning" class="lib_examples" id="BoardPanel3" style="display: none;">

                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Overall score for each category under different threshold.
                  </md-block>
                  <!-- </div> -->
                  <div class="table-container">
                    <table>
                      <thead>
                        <tr>
                          <th rowspan="2">Cat.</th>
                          <th colspan="3">Use. Imp.</th>
                          <th colspan="3">Lat. Inf.</th>
                          <th colspan="3">Pro. Cap.</th>
                          <th colspan="3">Mod. Mis.</th>
                          <th colspan="3">Int. Sen</th>
                          <th colspan="3">Sel. Ide.</th>
                        </tr>
                        <tr>
                          <th>5</th>
                          <th>6</th>
                          <th>7</th>
                          <th>5</th>
                          <th>6</th>
                          <th>7</th>
                          <th>5</th>
                          <th>6</th>
                          <th>7</th>
                          <th>5</th>
                          <th>6</th>
                          <th>7</th>
                          <th>5</th>
                          <th>6</th>
                          <th>7</th>
                          <th>5</th>
                          <th>6</th>
                          <th>7</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr class="section-header">
                          <td colspan="19"><strong>Llama3-8b</strong></td>
                        </tr>
                        <tr>
                          <td><strong>Raw</strong></td>
                          <td>—</td>
                          <td>8.70</td>
                          <td>—</td>
                          <td>—</td>
                          <td>2.90</td>
                          <td>—</td>
                          <td>—</td>
                          <td>5.25</td>
                          <td>—</td>
                          <td>—</td>
                          <td>1.60</td>
                          <td>—</td>
                          <td>—</td>
                          <td>4.00</td>
                          <td>—</td>
                          <td>—</td>
                          <td>7.30</td>
                          <td>—</td>
                        </tr>
                        <tr class="bold">
                          <td><strong>Direct</strong></td>
                          <td>8.15</td>
                          <td>8.70</td>
                          <td>8.90</td>
                          <td>4.10</td>
                          <td>4.15</td>
                          <td>5.50</td>
                          <td>5.00</td>
                          <td>5.00</td>
                          <td>5.55</td>
                          <td>5.15</td>
                          <td>5.60</td>
                          <td>5.00</td>
                          <td>7.55</td>
                          <td>8.15</td>
                          <td>7.50</td>
                          <td>8.05</td>
                          <td>7.85</td>
                          <td><strong>9.15</strong></td>
                        </tr>
                        <tr>
                          <td><strong>Stage-1</strong></td>
                          <td><strong>9.20</strong></td>
                          <td>7.80</td>
                          <td>8.05</td>
                          <td>3.10</td>
                          <td>4.50</td>
                          <td>2.95</td>
                          <td>4.30</td>
                          <td>3.85</td>
                          <td>4.55</td>
                          <td>3.45</td>
                          <td>4.75</td>
                          <td>5.85</td>
                          <td>3.85</td>
                          <td>5.80</td>
                          <td>6.55</td>
                          <td>6.35</td>
                          <td>6.40</td>
                          <td>6.50</td>
                        </tr>
                        <tr>
                          <td><strong>Stage-2</strong></td>
                          <td>8.90</td>
                          <td><strong>9.15</strong></td>
                          <td><strong>9.15</strong></td>
                          <td><strong>8.10</strong></td>
                          <td><strong>8.05</strong></td>
                          <td><strong>7.05</strong></td>
                          <td><strong>5.95</strong></td>
                          <td><strong>6.50</strong></td>
                          <td><strong>5.85</strong></td>
                          <td><strong>7.30</strong></td>
                          <td><strong>8.40</strong></td>
                          <td><strong>8.15</strong></td>
                          <td><strong>8.25</strong></td>
                          <td><strong>8.40</strong></td>
                          <td><strong>8.50</strong></td>
                          <td><strong>9.10</strong></td>
                          <td><strong>8.85</strong></td>
                          <td>8.90</td>
                        </tr>
                        <tr class="section-header">
                          <td colspan="19"><strong>Mistral-7b</strong></td>
                        </tr>
                        <tr>
                          <td><strong>Raw</strong></td>
                          <td>—</td>
                          <td>6.30</td>
                          <td>—</td>
                          <td>—</td>
                          <td>2.90</td>
                          <td>—</td>
                          <td>—</td>
                          <td>3.40</td>
                          <td>—</td>
                          <td>—</td>
                          <td>2.00</td>
                          <td>—</td>
                          <td>—</td>
                          <td>1.70</td>
                          <td>—</td>
                          <td>—</td>
                          <td>4.60</td>
                          <td>—</td>
                        </tr>
                        <tr class="bold">
                          <td><strong>Direct</strong></td>
                          <td><strong>8.70</strong></td>
                          <td>8.55</td>
                          <td><strong>8.45</strong></td>
                          <td>5.30</td>
                          <td>4.50</td>
                          <td><strong>6.10</strong></td>
                          <td><strong>6.00</strong></td>
                          <td><strong>5.40</strong></td>
                          <td><strong>6.25</strong></td>
                          <td>6.00</td>
                          <td>6.90</td>
                          <td>7.05</td>
                          <td>6.20</td>
                          <td><strong>7.10</strong></td>
                          <td>7.25</td>
                          <td>7.40</td>
                          <td>7.40</td>
                          <td>8.30</td>
                        </tr>
                        <tr>
                          <td><strong>Stage-1</strong></td>
                          <td>7.80</td>
                          <td>8.05</td>
                          <td>7.30</td>
                          <td>3.20</td>
                          <td>4.60</td>
                          <td>2.95</td>
                          <td>3.65</td>
                          <td>3.75</td>
                          <td>4.40</td>
                          <td>5.20</td>
                          <td>4.95</td>
                          <td>6.40</td>
                          <td>2.90</td>
                          <td>4.55</td>
                          <td>6.60</td>
                          <td>5.10</td>
                          <td>5.35</td>
                          <td>4.65</td>
                        </tr>
                        <tr>
                          <td><strong>Stage-2</strong></td>
                          <td>8.00</td>
                          <td><strong>8.70</strong></td>
                          <td>8.40</td>
                          <td><strong>6.40</strong></td>
                          <td><strong>6.30</strong></td>
                          <td>5.50</td>
                          <td>5.75</td>
                          <td>4.90</td>
                          <td>5.45</td>
                          <td><strong>7.95</strong></td>
                          <td><strong>8.00</strong></td>
                          <td><strong>7.55</strong></td>
                          <td>5.65</td>
                          <td>6.85</td>
                          <td><strong>8.05</strong></td>
                          <td><strong>8.55</strong></td>
                          <td><strong>8.55</strong></td>
                          <td><strong>8.50</strong></td>
                        </tr>
                      </tbody>
                    </table>
                  </div>

                </div>

                <div title="Ablation Study for Curriculum Learning" class="lib_examples" id="BoardPanel4"
                  style="display: none;">

                  <!-- <div class="content has-text-justified"> -->
                  <md-block>
                    Overall score and honesty rates of Llama3-8b and Mistral-7b under different thresholds.
                  </md-block>
                  <!-- </div> -->

                  <img src="img/curriculum-training.png" width="100%" alt="environment infrastructure"
                    class="responsive-image">
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="Empirical Result">
    <div class="container is-max-desktop">
      <div class="featurecard-container">
        <h1 class="title">Empirical Results</h1>
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Significant Improvements in Honesty Rates for LLMs with Training-Free Approach</h2>
          </div>
          <div class="description">
            <p>
              We significantly enhance the honesty rates
              in both open-source and proprietary LLMs by implementing our proposed training-free approach.
              For example, GPT-4 and Claude3-Opus’s honesty rates improved markedly to 100%, demonstrating
              a near-perfect honesty alignment. Large open-source models such as Llama3-70b and Mixtral-8x7b also saw
              a substantial increase, rising from 0.606 to 0.871 and 0.585 to 0.914 respectively.
              Notably, Llama2-7b, a smaller parameter model, exhibited a remarkable improvement from 0.430 to
              0.837. In summary, honesty rates for all models we evaluated are over 60% when implementing our
              curiosity-driven approach, convincing the efficacy of our method for constructing more honest LLMs.
            </p>
          </div>
        </div>

        <!-- Alignment of LLMs -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Enhanced Honesty and Helpfulness in LLMs with Curiosity-Driven Method: H2 Assessment Results</h2>
          </div>
          <div class="description">
            <p>
              In addition to honesty rates, we leverage LLM-as-a-Judge to conduct H2 assessment in both pairwise and
              score settings to evaluate the responses before and after the curiosity-driven method. In the pairwise
              setting, optimized answers were generally rated higher than the original ones, representing better honesty
              and helpfulness. Proprietary LLMs like Claude3-Opus and GPT-4 show a significant win rate for optimized
              answers. Open-source models like Llama2-7b showed that 40.1% of the optimized answers were preferred over
              the raw ones. In the score setting, we provide fine-grained scores for three principles. All LLMs
              demonstrate improvement using our training-free method, with proprietary models achieving significantly
              better results than open-source models, scoring over 9 in ‘Explanation’ and over 8 in ‘Guidance’. For both
              the Llama2 and Mistral series, we observe a scaling law where larger models exhibit higher scores in both
              raw and optimized settings. Among the three dimensions, ‘Explanation’ and ‘Guidance’ show the most
              substantial improvement, indicating that models become more honest and helpful in identifying their
              limitations and guiding users through LLM-unable questions.
            </p>
          </div>
        </div>

        <!-- Performance Gap in Trustworthiness -->
        <div class="feature_1x1">
          <div class="featurecard">
            <h2>Two-Stage Fine-Tuning Method Boosts Honesty and H2 Scores in Open-source Models</h2>
          </div>
          <div class="description">
            <p>
              Our proposed two-stage fine-tuning method demonstrates improvements in honesty rate and H2 assessment for
              both Llama3-8B and Mistral-7B. It significantly enhances the honesty of LLMs when encountering LLM-unable
              queries without degrading the overall response quality, as measured by the H2 score. Specifically, the
              Llama3-8b model shows a notable improvement of 13.7% in honesty rates post fine-tuning, along with an 8.5%
              increase in the H2 score. Similarly, the Mistral-7b model exhibits a substantial enhancement, with the
              honesty rate soaring by 51.9% and the H2 score escalating by 108.6% after the two-stage fine-tuning
              process. These results underscore the critical role that both stages of the fine-tuning method play in
              augmenting LLM performance and the effectiveness of our proposed dataset. Empirical results show the
              overall scores and honesty rates for the two LLMs under different thresholds. Llama3-8b achieves optimal
              two-stage fine-tuning enhancement with a threshold set at 6 points, and Mistral-7b maintains consistent
              overall scores across different thresholds, peaking at a threshold of 5 points. Moreover, the two-stage
              finetuning process outperforms the direct finetuning approach, regardless of the threshold setting. Both
              models achieve the highest overall scores in the category “user input not enough or with wrong
              information", while the data from the category “modality mismatch" and “interactivity sensory processing”
              gain the most scores. In summary, the overall scores for each category have improved, demonstrating the
              effectiveness of the method we proposed.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h1 class="title">BibTeX</h1>
      <pre><code>@misc{gao2024bestworldshonesthelpful,
        title={The Best of Both Worlds: Toward an Honest and Helpful Large Language Model}, 
        author={Chujie Gao and Qihui Zhang and Dongping Chen and Yue Huang and Siyuan Wu and Zhengyan Fu and Yao Wan and Xiangliang Zhang and Lichao Sun},
        year={2024},
        eprint={2406.00380},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2406.00380}, 
  }</code></pre>
    </div>
  </section>
  <div class="content">
    <div id="supportContainer">
      <h1 class="supportTitle">HonestLLM Team</h1>
      <br>

      <div id="logoContainer">
        <img src="img/logos/HUST.png" alt="School 1" class="schoolLogo">
        <img src="img/logos/Lehigh-University-logo.png" alt="School 2" class="schoolLogo">
        <img src="img/logos/ND.png" alt="School 3" class="schoolLogo">

      </div>


    </div>
  </div>
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
            </p>
            <p>This website is based on templates in <a href="https://trustllmbenchmark.github.io/TrustLLM-Website/">TrustLLM</a> and <a href="https://os-world.github.io/">OSWorld</a>.</p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>